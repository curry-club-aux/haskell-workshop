% Kompilieren mit: pdflatex -shell-escape uebung
\documentclass{uebblatt}

\begin{document}

\maketitle{Zweiter Haskell-Workshop}{Learn You a Haskell for Great Good!}

\section{Statistisch aussagekräftige Benchmarks}

Die Haskell-Community liebt die Bibliothek \emph{Criterion}, um die Laufzeit
von Haskell-Programmen zu messen. Diese macht viel mehr, als nur gegebenen Code
mehrmals auszuführen und dann die durchschnittliche Laufzeit zu berechnen. Sie
bestimmt auch die Standardabweichung der Laufzeit und gibt ein statistisches
Maß für die Verlässlichkeit der geschätzten Werte aus.

Ihre Benutzung ist kinderleicht:

\begin{enumerate}
\item[1.] \texttt{stack install criterion}
\item[2.] Folgende Vorlage anpassen:

\begin{haskellcode}
import Criterion.Main

fib :: Integer -> Integer
fib = ...

main = defaultMain
    [ bgroup "fib"
        [ bench "10" $ whnf fib 10
        , bench "20" $ whnf fib 20
        , bench "30" $ whnf fib 30
        ]
    ]
\end{haskellcode}

\item[3.] Das Programm ausführen. Wenn man dabei die Option \texttt{--output
foo.html} übergibt, erstellt die Criterion-Bibliothek eine interaktive
HTML-Seite, der man unter anderem die Verteilung der Messwerte entnehmen kann.
\end{enumerate}


\section{Erste Schritte mit Nebenläufigkeit}

Da es in Haskell keinen veränderlichen Zustand gibt, können Haskell-Ausdrücke
in erster Näherung in beliebiger Reihenfolge und auf beliebigen Prozessorkernen
ausgewertet werden. GHC verteilt aber nicht von selbst Aufgaben auf mehrere
Kerne.

Es gibt in Haskell vier verschiedene Möglichkeiten, Nebenläufigkeit zu
erreichen, die man je nach Anwendungszweck einsetzen kann.

\begin{itemize}
\item Parallelisierungsannotationen. Puren Code kann man einfach und ohne
Umstrukturierung des Programms mit Auswertungsannotationen versehen, wie zum
Beispiel "`führe das folgende \haskellinline{map} parallel aus"' oder "`falls
Ressourcen vorhanden sind, beginne die Auswertung des folgenden Ausdrucks im
Hintergrund"'.
\item Threads. Wie in anderen Sprachen auch kann man explizit Threads
erstellen. Threads können auf diverse Weisen miteinander kommunizieren, zum
Beispiel mittels gemeinsamer veränderlicher Variablen (\haskellinline{MVar})
und Channels (\haskellinline{Chan}). Dieser recht explizite Zugang zu
Nebenläufigkeit ist also sehr ähnlich zum Zugang von anderen Sprachen wie
Python oder JavaScript mit Node.js. Anders als in diesen Sprachen gibt es aber
keine "`Callback-Hölle"'.
\item Shared Transactional Memory (STM). Parallelisierungsannotationen helfen
nicht bei Code, der Nebenwirkungen verursachen muss. Wenn man aber auf Threads
zurückgreifen würde, müsste man wie in anderen Sprachen auch auf korrektes
Locking und Race Conditions achten; das ist mühsam und fehleranfällig. STM ist
eine Technik, mit der man vorgeben kann, dass speziell gekennzeichneter Code so
abläuft, als wäre das Programm rein sequenziell geschrieben. Der große Vorteil
an STM ist \emph{Kompositionalität}: Man kann Code rein lokal verstehen und
kombinieren, ohne auf Auswirkungen von parallel ablaufenden Programmteilen
achten zu müssen.
\item Data Parallel Haskell (DPH). Dabei kümmern sich der Compiler und die
Laufzeitumgebung selbstständig um eine effiziente Verteilung des auszuwertenden
Codes. DPH ist ein Forschungsprojekt, das noch nicht seinen Weg in die
aktuelle GHC-Version gefunden hat.
\end{itemize}


\subsection{Parallelisierungsannotationen}

Aus dem ersten Workshop ist ja die Funktion \haskellinline{seq :: a -> b -> b}
bekannt. Wird der Ausdruck \haskellinline{seq x y} ausgewertet, so wird
zunächst~\haskellinline{x} ausgewertet, das Ergebnis verworfen, und
dann~\haskellinline{y} zurückgegeben.

Ein Aufruf wie \haskellinline{seq 42 y} ist nicht besonders sinnvoll. Wenn aber
die Auswertung von~\haskellinline{x} die Auswertung von Teilen einer
Datenstruktur anstößt, so bleiben die Ergebnisse gespeichert. Die folgende
GHCi-Sitzung illustriert das:

\begin{verbatim}
> let x = fib 30  -- kehrt sofort zurück
> seq x "Hallo"   -- dauert lange, da `x` ausgewertet wird
"Hallo"
> x               -- kehrt sofort zurück
832040
\end{verbatim}

Nun gibt es neben \haskellinline{seq} auch die Funktion \haskellinline{par :: a
-> b -> b} aus dem Modul \haskellinline{Control.Parallel} (aus dem Paket
\texttt{parallel}). Semantisch ist~\haskellinline{par x y} identisch
zu~\haskellinline{y}. Als Nebenwirkung wird aber ein \emph{Spark} erzeugt,
der~\haskellinline{x} im Hintergrund parallel auswertet.

In GHCi sieht das zum Beispiel so aus:

\begin{verbatim}
> let fib :: Int -> Int; fib n = if n <= 1 then n else fib (n-1) + fib (n-2)
> let x = fib 30
> let y = fib 30
> (x,y)
(832040,832040)   -- die beiden Komponenten werden nacheinander
                  -- berechnet und ausgegeben

> import Control.Parallel
> let a = fib 30
> let b = fib 30
> b `par` (a,b)
(832040,832040)   -- nach anfänglicher Verzögerung werden beide
                  -- Komponenten in einem Rutsch ausgegeben
\end{verbatim}

\emph{Wichtig:} Standardmäßig verwendet die Laufzeitumgebung nur einen einzigen
Betriebssystem-Thread. Damit können keine Sparks im Hintergrund ausgeführt
werden. Man muss seinen Code mit der Option \texttt{-threaded} kompilieren und
beim Ausführen dem Laufzeitsystem mitteilen, dass es mehrere
Betriebssystem-Threads verwenden soll:

\begin{verbatim}
# Kompilieren mit:
$ ghc --make -O2 -threaded Main

# Ausführen mit:
$ ./Main +RTS -N4 -RTS   # genau vier Betriebssystem-Threads verwenden
$ ./Main +RTS -N -RTS    # sinnvolle Anzahl Betriebssystem-Threads verwenden

# Interaktive Shell:
$ ghci +RTS -N -RTS
\end{verbatim}

\begin{aufgabe}{Was bedeutet eigentlich Auswertung?}
Erkläre, wieso in folgender GHCi-Sitzung scheinbar~\haskellinline{b}
\emph{nicht} im Hintergrund ausgewertet wird. Denke daran, GHCi mit der Option
\texttt{+RTS -N -RTS} zu starten.

\begin{verbatim}
> import Control.Parallel
> let a = [fib 30]
> let b = [fib 30]
> b `par` (a,b)
([832040],[832040])
\end{verbatim}
\end{aufgabe}

\begin{aufgabe}{Paralleles Map}
Schreibe eine Funktion \haskellinline{parMap :: (a -> b) -> [a] -> [b]}, die
semantisch identisch zu~\haskellinline{map} ist, aber alle Werte parallel
berechnet.

Auf einem Mehrkern-Computer sollte also
\begin{verbatim}
> parMap fib [30,30,30,30]
\end{verbatim}
deutlich schneller ablaufen als~\haskellinline{map fib [30,30,30,30]}.
\end{aufgabe}

Zu Sparks ist noch viel mehr zu sagen. An dieser Stelle nur zwei Bemerkungen:
Startet man sein Programm mit den Optionen \texttt{+RTS -N -s -RTS}, so werden
nach Beendigung Statistiken ausgegeben. Diese beinhalten unter anderem, wie
viele Sparks erzeugt wurden und wie viele \emph{fizzelten} -- das heißt, dass
der zu berechnende Wert schon vom Hauptthread angefordert wurde, noch bevor der
Spark loslegen konnte.

Außerdem gibt es \emph{ThreadScope}, mit dem die Auslastung durch Threads und
Sparks visualisiert werden kann.

\begin{center}
  \href{https://wiki.haskell.org/ThreadScope_Tour/Spark}{\includegraphics[width=0.8\textwidth]{Spark-lifecycle}}

  Der Lebenszyklus eines Sparks.
  Quelle: \url{https://wiki.haskell.org/ThreadScope_Tour/Spark}
\end{center}


\subsection{Threads}

Mit \haskellinline{forkIO :: IO a -> IO ThreadId} aus dem Modul
\haskellinline{Control.Concurrent} erzeugt man einen \emph{leichtgewichtigen
Thread}. Die übergebene IO-Aktion wird in diesem Thread ausgeführt;
Rückgabewert ist ein Wert vom Typ \haskellinline{ThreadId}, mit dem man den
Thread noch nachträglich kontrollieren (etwa vorzeitig beenden) kann.

Die Laufzeitumgebung kommt mit sehr vielen -- Millionen -- von
leichtgewichtigen Threads klar. Sie werden auf eine kleine Anzahl
echter Threads auf Betriebssystem-Level verteilt.

In speziellen Anwendungsfällen ist es nötig, Betriebssystem-Threads statt
leichtgewichtiger Threads zu erzeugen. Das ist mittels der Funktion
\haskellinline{forkOS :: IO a -> IO ThreadId} ebenfalls möglich.

\emph{Wichtig:} Wenn man Threads nur verwenden möchte, um mit simultan
stattfindenden IO-Aktionen umzugehen (etwa Anforderungen mehrerer gleichzeitig
verbundener Clients über das Netzwerk entgegennehmen), genügt prinzipiell ein
einzelner Betriebssystem-Thread. Wenn man aber mit Threads
tatsächlich auch mehrere Berechnungen parallel ausführen möchte, muss man
wie im vorherigen Abschnitt beschrieben seinen Code mit der Option
\texttt{-threaded} kompilieren und beim Ausführen
dem Laufzeitsystem mit \texttt{+RTS -N -RTS} mitteilen, mehrere
Betriebssystem-Threads zu verwenden.

\begin{aufgabe}{Hallo Welt aus zwei Threads}
Schreibe ein Haskell-Programm, das einen leichtgewichtigen Thread erzeugt
und den ausführenden Lambroiden sowohl vom Hauptthread als auch dem erzeugten
Thread mit \haskellinline{putStrLn} grüßt.
\end{aufgabe}

\begin{aufgabe}{Vermischte Ausgabe}
Schreibe ein Haskell-Programm, das zwei leichtgewichtige Threads erzeugt. Der
eine Thread soll tausendmal das Zeichen \haskellinline{'a'} ausgeben, der
andere das Zeichen \haskellinline{'b'}. Was passiert?
\end{aufgabe}

\begin{aufgabe}{Sleep Sort}
Implementiere \emph{Sleep Sort}: Erzeuge für jedes
Element~\haskellinline{x} einer gegebenen Liste von (kleinen) natürlichen
Zahlen einen Thread, der sich gleich nach seiner Erstellung für eine
zu~\haskellinline{x} proportionale Zeit schlafen legt und
anschließend~\haskellinline{x} auf dem Terminal ausgibt.

{\scriptsize\emph{Tipp.} Verwende die Funktion \haskellinline{threadDelay ::
Int -> IO ()}, die den momentan laufenden Thread für eine gegebene Anzahl
Mikrosekunden schlafen legt.\par}
\end{aufgabe}

Eine primitive Möglichkeit der Kommunikation zwischen Threads sind
(thread-sichere) veränderliche Variablen. Eine solche kann zu jedem Zeitpunkt
leer sein oder einen Wert enthalten. Man erstellt sie mit
\haskellinline{newEmptyMVar :: IO (MVar a)} oder, wenn man die Variable gleich
initialiseren möchte, mit \haskellinline{newMVar :: a -> IO (MVar a)}.

Mit \haskellinline{readMVar :: MVar a -> IO a} holt man den aktuellen Wert
einer übergebenen Variable. Sollte die Variable leer sein, blockiert dieser
Aufruf so lange, bis die Variable durch einen anderen Thread gefüllt wird.

Eine Variante ist die Funktion \haskellinline{takeMVar :: MVar a -> IO a}, die
nach Auslesen der Variable diese leert.

Mit \haskellinline{putMVar :: MVar a -> a -> IO ()} setzt man den Inhalt einer
Variable. Wenn diese zum Zeitpunkt des Aufrufs nicht leer sein sollte, wird der
vorhandene Inhalt nicht überschrieben. Stattdessen wird der ausführende Thread
so schlafen gelegt, bis ein anderer Thread die Variable mit
\haskellinline{takeMVar} leert. (Es gibt auch \haskellinline{tryPutMVar :: MVar
-> a -> IO Bool}, das den Thread nicht schlafen geht und den Erfolg durch den
Rückgabewert anzeigt.)

\begin{aufgabe}{Lesen aus einer dauerhaft leeren Variable}
Was macht folgender Code? Wie reagiert das Laufzeitsystem von GHC?

\begin{haskellcode}
import Control.Concurrent

main = do
    ref <- newEmptyMVar
    takeMVar ref
\end{haskellcode}
\end{aufgabe}

\begin{aufgabe}{Ein einfaches Beispiel zu Variablen}
Schreibe ein Programm, das zwei leichtgewichtigen Threads erzeugt, die je eine große
Fibonacci-Zahl berechnen und das Ergebnis in je einer Variable speichern. Der
Hauptthread soll dann die beiden Ergebnisse ausgeben.
\end{aufgabe}

\begin{aufgabe}{Vorsicht vor Deadlocks}
Was macht folgender Code? Wie reagiert das Laufzeitsystem von GHC?

\begin{haskellcode}
import Control.Concurrent

main = do
    ref1 <- newEmptyMVar
    ref2 <- newEmptyMVar
    forkIO $ takeMVar ref2 >> putMVar ref1 "Hallo Welt"
    putStrLn =<< takeMVar ref1
\end{haskellcode}
\end{aufgabe}

\begin{aufgabe}{Warten auf Kinder}
Oft möchte man im Hauptthread die Beendigung gestarteter Threads abwarten. Das
ist zum Beispiel mit folgendem Code möglich (den es natürlich auch schon in
verpackter Form im Modul \haskellinline{Control.Concurrent.Async} gibt).
Vollziehe ihn nach!

\begin{haskellcode}
import Control.Monad
import Control.Concurrent

forkThread :: IO () -> IO (MVar ())
forkThread proc = do
    ref <- newEmptyMVar
    forkFinally proc $ \_ -> putMVar ref ()
    return ref

main = do
    jobs <- mapM forkThread [...]
    mapM_ takeMVar jobs
\end{haskellcode}
\end{aufgabe}

Neben veränderlichen Variablen gibt es noch \emph{Kanäle} zur Kommunikation
zwischen Threads. Kanäle können anders als Variablen mehr als einen Wert
zwischenspeichern. Man erzeugt einen Kanal mit \haskellinline{newChan :: IO
(Chan a)}, pusht einen Wert durch \haskellinline{writeChan :: Chan a -> a ->
IO ()} und poppt den vordersten Wert mit \haskellinline{readChan :: Chan a ->
IO a}. Der Aufruf von \haskellinline{readChan} blockiert, falls der Kanal leer
ist.

\begin{aufgabe}{Sleep Sort kanalbasiert}
Modifiziere deinen Sleep-Sort-Algorithmus derart, dass die sortierten Werte
nicht auf dem Terminal ausgegeben, sondern in einen Kanal geschrieben werden.
Dieser soll dann in einem Rutsch ausgegeben werden. 
\end{aufgabe}

Zum Ende dieses Abschnitts sei bemerkt, dass man selten auf der Ebene dieser
Aufgaben programmieren muss. Für viele Einsatzgebiete gibt es schon fertige
Kombinatoren-Bibliotheken zum nebenläufigen Programmieren.

\begin{aufgabe}{Projekt: Ein einfacher Chat-Server}
Vervollständige folgende Vorlage für einen einfachen Chat-Server. Clients
sollen sich mit ihm auf TCP-Port~4242 verbinden können. Eingehende Nachrichten
sollen an alle verbundenen Clients weitergeleitet werden.

Diese Vorlage ist auf einem niedrigen Level, mit expliziten Socket-Operationen,
geschrieben. Normalerweise würde man eine High-Level-Streaming-Bibliothek wie
Conduits oder Pipes verwenden. Diese kümmern sich auch automatisch um
ordnungsgemäßes Abmelden von Clients.

{\scriptsize\emph{Tipp.} Verwende die Funktion \haskellinline{dupChan :: Chan a
-> IO (Chan a)}. \emph{Bonusaufgabe.} Identifiziere das Speicherleckproblem und
löse es.\par}

\begin{haskellcode}
module Main where

import Control.Monad
import Control.Concurrent
import Network.Socket
import System.IO

main :: IO ()
main = do
    -- Lausche auf Port 4242.
    sock <- socket AF_INET Stream 0
    setSocketOption sock ReuseAddr 1
    bindSocket sock (SockAddrInet 4242 iNADDR_ANY)
    listen sock 10

    -- Setze einen Kanal auf. Was in diesen Kanal geschrieben wird,
    -- soll an alle verbundenen Clients weitergeleitet werden.
    ...

    -- Die Hauptschleife: Akzeptiere laufend neue Verbindungen und
    -- bearbeite sie.
    forever $ do
        (conn,_) <- accept sock
        hdl      <- socketToHandle conn ReadWriteMode
        hSetBuffering hdl NoBuffering
        -- `hdl` ist nun ein gewöhnlicher Handle, mit dem `hGetLine`
        -- und `hPutStrLn` verwendet werden können.

        -- Dupliziere den Kanal, um mehrere Zuhörer zu unterstützen.
        ...

        -- Schreibe gelesene Nachrichten in den Kanal.
        forkIO $ forever $ do
            msg <- hGetLine hdl
            ...

        -- Leite Nachrichten der anderen Verbindungen weiter.
        forkIO $ forever $ do
            ...
            hPutStrLn hdl msg
\end{haskellcode}
\end{aufgabe}


\subsection{Shared Transactional Memory (STM)}

In dem folgenden Programm kommt es zu einer Race Condition. Wiederholte Aufrufe
des Programms werden verschiedene Ergebnisse liefern.

\begin{haskellcode}
import Control.Concurrent
import Control.Monad

forkThread :: IO () -> IO (MVar ())
forkThread = {- siehe oben -}

go :: IORef Integer -> IORef Integer -> IO ()
go xRef yRef = do
    x <- readIORef xRef
    y <- readIORef yRef
    let x' = y  + 1
        y' = x' + 1
    writeIORef xRef x'
    writeIORef yRef y'

main = do
    xRef <- newIORef 1
    yRef <- newIORef 2
    jobs <- replicateM 40000 $ forkThread $ go xRef yRef
    mapM_ takeMVar jobs
    x <- readIORef xRef
    y <- readIORef yRef
    print (x, y)
\end{haskellcode}

Mit STM passiert das nicht. Statt \haskellinline{IORef}'s verwendet man dann
\haskellinline{TVar}'s. Die Operationen übertragen sich wörtlich, spielen sich
dann aber in der \haskellinline{STM}- statt der \haskellinline{IO}-Monade ab:
\haskellinline{newTVar :: a -> STM (TVar a)} und so weiter. Man führt
STM-Aktionen mit \haskellinline{atomically :: STM a -> IO a} aus.

Der angepasste Code sieht so aus:

\begin{haskellcode}
import Control.Concurrent
import Control.Concurrent.STM
import Control.Monad

forkThread :: IO () -> IO (MVar ())
forkThread = {- siehe oben -}

go :: TVar Integer -> TVar Integer -> STM ()
go xRef yRef = do
    x <- readTVar xRef
    y <- readTVar yRef
    let x' = y  + 2
        y' = x' + 2
    writeTVar xRef x'
    writeTVar yRef y'

main = do
    xRef <- newTVarIO 1
    yRef <- newTVarIO 2
    jobs <- replicateM 40000 $ forkThread $ atomically $ go xRef yRef
    mapM_ takeMVar jobs
    x <- readTVarIO xRef
    y <- readTVarIO yRef
    print (x, y)
\end{haskellcode}

Wie funktioniert STM? In erster Näherung so: Wird ein
\haskellinline{atomically}-Block ausgeführt, so werden Änderungen an
\haskellinline{TVar}'s nicht sofort geschrieben. Stattdessen werden sie in
einem Log notiert. Am Ende des Blocks prüft das Laufzeitsystem in einer
atomaren Operation, ob sich seit Ablauf des Blocks seine Abhängigkeiten (zum
Beispiel veränderliche Variablen, auf die lesend zugegriffen wurde) geändert
haben. Wenn nein, macht es die Änderungen an den \haskellinline{TVar}'s
wirksam. Wenn ja, wird der Block einfach erneut ausgeführt. Da in der
STM-Monade nicht beliebige Nebenwirkungen wie \haskellinline{fireMissiles}
möglich sind, ist das ein fundiertes Vorgehen.

\end{document}

XXX: Ein paar Aufgaben zu `par` und `pseq` verfassen.
